# FRED Cleaning Exercise 
## Overview: 
The FRED cleaning exercise project leverages  economic indicators to predict key macroeconomic trends, such as GDP growth, inflation, and unemployment rates.The goal of this project was to demonstrate the ability to clean, preprocess, analyze, and visualize economic data, specifically focusing on the relationship between key indicators like GDP, unemployment rate, inflation, and other macroeconomic factors over time. The project also involved aggregating monthly data into yearly data and analyzing the correlation between these variables.
## Problem Statement: 
The economy is influenced by many factors, and predicting economic outcomes is crucial for informed decision-making. However, the complex interactions between variables like GDP, inflation, unemployment, and consumer spending can make predictions challenging. The objective of this project is to practice pulling relevant data factors (such as GDP, unemployment rate, and consumer inflation) from different sources, clean, pre-process and merge that data to create a clean dataset that can be used for further statistically significant analysis. 
## Learning Objectives: 
1. __Data Processing:__ Use advanced techniques with Pandas to preprocess and clean large, complex datasets.
2. __Data Visualization:__ Use Matplotlib and Seaborn for creating visualizations that highlight trends, correlations, and model results.
3. __Correlation Analysis:__ Perform correlation analysis to understand the relationships between different macroeconomic variables.
## Technologies Used:
Python: Primary language for data processing, model training, and evaluation.

Pandas: For data manipulation and preprocessing of large datasets.

Scikit-learn: For machine learning algorithms and evaluation metrics.

Matplotlib / Seaborn: For visualizing the dataset and results.

Jupyter Notebooks: For interactive development, data exploration, and visualization.

## Learner Growth: 
This project provided valuable hands-on experience in working with economic datasets and preparing them for further analysis. I gained insight into how to pull, clean, and merge data from different sources to create a unified dataset. I also learned how to:

- Efficiently preprocess and clean complex economic data using Pandas, ensuring it was ready for analysis.
- Aggregate monthly data into yearly data and manage time series data effectively.
- Perform correlation analysis to identify relationships between key macroeconomic indicators like GDP, inflation, and unemployment rates.
- Create meaningful visualizations using Matplotlib and Seaborn to communicate trends and relationships between variables.
- Understand how different macroeconomic indicators influence each other over time, and how this can inform decision-making in economics and policymaking.

## Potential Questions: 
- How do key economic indicators like GDP, unemployment rate, and inflation rate correlate with each other over time?
- Can we identify any significant lag effects between these indicators (e.g., does a change in unemployment rate precede a change in GDP)?
- How can this cleaned and aggregated dataset be used to build predictive models or inform economic policy?
- Are there any observable trends or cycles in the data (e.g., seasonal patterns, long-term growth/decline)?
- What other external factors or economic indicators could be incorporated to improve the accuracy of forecasts or the analysis?
- Are there any anomalies in the dataset that need further investigation, and what impact might they have on predictions?

## Timeline: 
This project took approximately 3 to 5 hours in total to complete. 

## License: 
This project is licensed under the MIT License. See the LICENSE file for details.
